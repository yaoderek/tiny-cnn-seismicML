{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d16f490",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41e263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from seaborn) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from seaborn) (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c17ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/marinedenolle/opt/miniconda3/envs/noisepy-deploy/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5f5f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "✓ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Add parent directory to path to import model\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from src.models.cnn import SeismicCNN, CompactSeismicCNN\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"\\n✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66638595",
   "metadata": {},
   "source": [
    "## Load Labeled Data\n",
    "\n",
    "Load the windowed seismograms and labels created by the multi-class labeling notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd6b9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:\n",
      "  Waveforms: windowed_waveforms_20251210_170458.npy\n",
      "  Labels: labels_20251210_170458.npy\n",
      "  Metadata: metadata_20251210_170458.csv\n",
      "\n",
      "✓ Data loaded successfully!\n",
      "  X shape: (719, 500)\n",
      "  y shape: (719,)\n",
      "\n",
      "Class distribution:\n",
      "  Noise (class 0): 300 samples (41.7%)\n",
      "  Traffic (class 1): 18 samples (2.5%)\n",
      "  Earthquake (class 2): 401 samples (55.8%)\n"
     ]
    }
   ],
   "source": [
    "# Find the most recent labeled dataset\n",
    "data_dir = Path(\"../02_labeling/labeled_data\")\n",
    "\n",
    "if not data_dir.exists():\n",
    "    raise FileNotFoundError(f\"Data directory '{data_dir}' not found. Run ../02_labeling/multi_class_labeling.ipynb first.\")\n",
    "\n",
    "# Find most recent files\n",
    "waveform_files = sorted(data_dir.glob(\"windowed_waveforms_*.npy\"))\n",
    "label_files = sorted(data_dir.glob(\"labels_*.npy\"))\n",
    "metadata_files = sorted(data_dir.glob(\"metadata_*.csv\"))\n",
    "\n",
    "if not waveform_files or not label_files:\n",
    "    raise FileNotFoundError(\"No labeled data found. Run multi_class_labeling.ipynb first.\")\n",
    "\n",
    "# Use most recent files\n",
    "waveforms_file = waveform_files[-1]\n",
    "labels_file = label_files[-1]\n",
    "metadata_file = metadata_files[-1] if metadata_files else None\n",
    "\n",
    "print(f\"Loading data from:\")\n",
    "print(f\"  Waveforms: {waveforms_file.name}\")\n",
    "print(f\"  Labels: {labels_file.name}\")\n",
    "if metadata_file:\n",
    "    print(f\"  Metadata: {metadata_file.name}\")\n",
    "\n",
    "# Load data\n",
    "X = np.load(waveforms_file)  # Shape: (n_samples, window_length)\n",
    "y = np.load(labels_file)     # Shape: (n_samples,)\n",
    "\n",
    "if metadata_file:\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "else:\n",
    "    metadata = None\n",
    "\n",
    "print(f\"\\n✓ Data loaded successfully!\")\n",
    "print(f\"  X shape: {X.shape}\")\n",
    "print(f\"  y shape: {y.shape}\")\n",
    "\n",
    "# Print class distribution\n",
    "class_names = ['Noise', 'Traffic', 'Earthquake']\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(f\"\\nClass distribution:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  {class_names[int(label)]} (class {int(label)}): {count} samples ({count/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d3420",
   "metadata": {},
   "source": [
    "## Prepare Data for Training\n",
    "\n",
    "Split data into train/validation/test sets and create PyTorch DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906cf1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X: (719, 1, 500)\n",
      "\n",
      "Data split:\n",
      "  Train: 503 samples (70.0%)\n",
      "  Val:   108 samples (15.0%)\n",
      "  Test:  108 samples (15.0%)\n",
      "\n",
      "Train class distribution:\n",
      "  Noise: 210 (41.7%)\n",
      "  Traffic: 13 (2.6%)\n",
      "  Earthquake: 280 (55.7%)\n",
      "\n",
      "Val class distribution:\n",
      "  Noise: 45 (41.7%)\n",
      "  Traffic: 2 (1.9%)\n",
      "  Earthquake: 61 (56.5%)\n",
      "\n",
      "Test class distribution:\n",
      "  Noise: 45 (41.7%)\n",
      "  Traffic: 3 (2.8%)\n",
      "  Earthquake: 60 (55.6%)\n",
      "\n",
      "✓ DataLoaders created with batch size: 32\n",
      "  Train batches: 16\n",
      "  Val batches: 4\n",
      "  Test batches: 4\n"
     ]
    }
   ],
   "source": [
    "# Add channel dimension for CNN: (n_samples, window_length) -> (n_samples, 1, window_length)\n",
    "X = X[:, np.newaxis, :]  # Add channel dimension\n",
    "\n",
    "print(f\"Reshaped X: {X.shape}\")\n",
    "\n",
    "# Split data: 70% train, 15% validation, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Val:   {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test:  {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Print class distribution per split\n",
    "for split_name, y_split in [(\"Train\", y_train), (\"Val\", y_val), (\"Test\", y_test)]:\n",
    "    print(f\"\\n{split_name} class distribution:\")\n",
    "    unique, counts = np.unique(y_split, return_counts=True)\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"  {class_names[int(label)]}: {count} ({count/len(y_split)*100:.1f}%)\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.LongTensor(y_val)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\n✓ DataLoaders created with batch size: {batch_size}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a06d9",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure training parameters and models to train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bcc424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration:\n",
      "  Input channels: 1\n",
      "  Input length: 500 samples\n",
      "  Number of classes: 3\n",
      "\n",
      "Training configuration:\n",
      "  Epochs: 50\n",
      "  Learning rate: 0.001\n",
      "  Weight decay: 0.0001\n",
      "  Batch size: 32\n",
      "\n",
      "✓ Will train 2 models: compact, standard\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "num_classes = 3\n",
    "input_channels = 1  # Single channel (vertical component)\n",
    "input_length = X_train.shape[2]  # Window length in samples\n",
    "\n",
    "print(f\"Model configuration:\")\n",
    "print(f\"  Input channels: {input_channels}\")\n",
    "print(f\"  Input length: {input_length} samples\")\n",
    "print(f\"  Number of classes: {num_classes}\")\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "batch_size = 32\n",
    "\n",
    "# Models to train\n",
    "models_to_train = ['compact', 'standard']  # Train both models\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Epochs: {num_epochs}\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Weight decay: {weight_decay}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"\\n✓ Will train {len(models_to_train)} models: {', '.join(models_to_train)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c554fc2",
   "metadata": {},
   "source": [
    "## Training Loop for Both Models\n",
    "\n",
    "Train both compact and standard models, saving each one separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f279ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights for loss function:\n",
      "  Noise: 0.168\n",
      "  Traffic: 2.707\n",
      "  Earthquake: 0.126\n",
      "\n",
      "######################################################################\n",
      "# TRAINING COMPACT MODEL\n",
      "######################################################################\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Training COMPACT Model (9,347 parameters)\n",
      "======================================================================\n",
      "Epoch  Train Loss   Train Acc    Val Loss     Val Acc      Time    \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "Training COMPACT Model (9,347 parameters)\n",
      "======================================================================\n",
      "Epoch  Train Loss   Train Acc    Val Loss     Val Acc      Time    \n",
      "----------------------------------------------------------------------\n",
      "1      0.9112       45.92        0.9591       61.11        0.42    s\n",
      "1      0.9112       45.92        0.9591       61.11        0.42    s\n",
      "2      0.8051       76.74        0.8003       71.30        0.41    s\n",
      "2      0.8051       76.74        0.8003       71.30        0.41    s\n",
      "3      0.7798       70.58        0.7562       69.44        0.40    s\n",
      "3      0.7798       70.58        0.7562       69.44        0.40    s\n",
      "4      0.7124       74.16        0.7014       75.93        0.38    s\n",
      "4      0.7124       74.16        0.7014       75.93        0.38    s\n",
      "5      0.6893       75.15        0.6798       76.85        0.37    s\n",
      "5      0.6893       75.15        0.6798       76.85        0.37    s\n",
      "6      0.6429       77.14        0.6503       81.48        0.38    s\n",
      "6      0.6429       77.14        0.6503       81.48        0.38    s\n",
      "7      0.6085       78.13        0.6391       81.48        0.38    s\n",
      "7      0.6085       78.13        0.6391       81.48        0.38    s\n",
      "8      0.5914       76.54        0.6468       77.78        0.37    s\n",
      "8      0.5914       76.54        0.6468       77.78        0.37    s\n",
      "9      0.5702       75.55        0.7269       83.33        0.37    s\n",
      "9      0.5702       75.55        0.7269       83.33        0.37    s\n",
      "10     0.5405       77.73        0.6119       79.63        0.41    s\n",
      "10     0.5405       77.73        0.6119       79.63        0.41    s\n",
      "11     0.5495       76.94        0.6314       75.00        0.38    s\n",
      "11     0.5495       76.94        0.6314       75.00        0.38    s\n",
      "12     0.5062       78.53        0.6395       83.33        0.38    s\n",
      "12     0.5062       78.53        0.6395       83.33        0.38    s\n",
      "13     0.4795       76.74        0.7382       82.41        0.37    s\n",
      "13     0.4795       76.74        0.7382       82.41        0.37    s\n",
      "14     0.4700       78.73        0.7400       68.52        0.37    s\n",
      "14     0.4700       78.73        0.7400       68.52        0.37    s\n",
      "15     0.4519       79.13        0.7085       82.41        0.37    s\n",
      "15     0.4519       79.13        0.7085       82.41        0.37    s\n",
      "16     0.3946       80.52        0.6099       81.48        0.37    s\n",
      "16     0.3946       80.52        0.6099       81.48        0.37    s\n",
      "17     0.4011       78.73        0.7023       82.41        0.38    s\n",
      "17     0.4011       78.73        0.7023       82.41        0.38    s\n",
      "18     0.3888       80.12        0.6244       79.63        0.37    s\n",
      "18     0.3888       80.12        0.6244       79.63        0.37    s\n",
      "19     0.4013       79.13        0.7488       83.33        0.38    s\n",
      "19     0.4013       79.13        0.7488       83.33        0.38    s\n",
      "20     0.3925       79.92        0.6489       75.00        0.46    s\n",
      "20     0.3925       79.92        0.6489       75.00        0.46    s\n",
      "21     0.3927       80.32        0.6516       82.41        0.39    s\n",
      "21     0.3927       80.32        0.6516       82.41        0.39    s\n",
      "22     0.3830       79.72        0.7424       83.33        0.41    s\n",
      "22     0.3830       79.72        0.7424       83.33        0.41    s\n",
      "23     0.3656       81.11        0.6360       80.56        0.39    s\n",
      "23     0.3656       81.11        0.6360       80.56        0.39    s\n",
      "24     0.3732       79.72        0.8436       82.41        0.39    s\n",
      "24     0.3732       79.72        0.8436       82.41        0.39    s\n",
      "25     0.3522       81.11        0.6318       76.85        0.41    s\n",
      "25     0.3522       81.11        0.6318       76.85        0.41    s\n",
      "26     0.3384       79.92        0.7617       82.41        0.39    s\n",
      "26     0.3384       79.92        0.7617       82.41        0.39    s\n",
      "27     0.3487       80.52        0.8085       82.41        0.37    s\n",
      "27     0.3487       80.52        0.8085       82.41        0.37    s\n",
      "28     0.3494       81.11        0.6680       81.48        0.40    s\n",
      "28     0.3494       81.11        0.6680       81.48        0.40    s\n",
      "29     0.3220       82.11        0.7321       79.63        0.39    s\n",
      "29     0.3220       82.11        0.7321       79.63        0.39    s\n",
      "30     0.3489       82.11        0.6475       80.56        0.40    s\n",
      "30     0.3489       82.11        0.6475       80.56        0.40    s\n",
      "31     0.3019       81.11        0.7923       82.41        0.40    s\n",
      "31     0.3019       81.11        0.7923       82.41        0.40    s\n",
      "32     0.3047       81.11        0.7839       82.41        0.40    s\n",
      "32     0.3047       81.11        0.7839       82.41        0.40    s\n",
      "33     0.3243       82.50        0.7075       81.48        0.40    s\n",
      "33     0.3243       82.50        0.7075       81.48        0.40    s\n",
      "34     0.3190       82.70        0.7129       80.56        0.44    s\n",
      "34     0.3190       82.70        0.7129       80.56        0.44    s\n",
      "35     0.3136       82.31        0.7362       80.56        0.38    s\n",
      "35     0.3136       82.31        0.7362       80.56        0.38    s\n",
      "36     0.3349       81.71        0.6877       80.56        0.37    s\n",
      "36     0.3349       81.71        0.6877       80.56        0.37    s\n",
      "37     0.3154       83.90        0.8716       82.41        0.39    s\n",
      "37     0.3154       83.90        0.8716       82.41        0.39    s\n",
      "38     0.3122       81.31        0.7153       80.56        0.40    s\n",
      "38     0.3122       81.31        0.7153       80.56        0.40    s\n",
      "39     0.2928       83.10        0.8277       82.41        0.38    s\n",
      "39     0.2928       83.10        0.8277       82.41        0.38    s\n",
      "40     0.2939       81.71        0.7148       81.48        0.38    s\n",
      "40     0.2939       81.71        0.7148       81.48        0.38    s\n",
      "41     0.2719       83.30        0.7666       82.41        0.38    s\n",
      "41     0.2719       83.30        0.7666       82.41        0.38    s\n",
      "42     0.2842       84.69        0.7931       82.41        0.40    s\n",
      "42     0.2842       84.69        0.7931       82.41        0.40    s\n",
      "43     0.2950       82.31        0.8401       82.41        0.39    s\n",
      "43     0.2950       82.31        0.8401       82.41        0.39    s\n",
      "44     0.2685       83.70        0.7534       82.41        0.39    s\n",
      "44     0.2685       83.70        0.7534       82.41        0.39    s\n",
      "45     0.2826       83.50        0.7687       82.41        0.40    s\n",
      "45     0.2826       83.50        0.7687       82.41        0.40    s\n",
      "46     0.2811       83.30        0.8463       81.48        0.38    s\n",
      "46     0.2811       83.30        0.8463       81.48        0.38    s\n",
      "47     0.2713       84.69        0.8161       81.48        0.40    s\n",
      "47     0.2713       84.69        0.8161       81.48        0.40    s\n",
      "48     0.2747       86.88        0.8158       82.41        0.38    s\n",
      "48     0.2747       86.88        0.8158       82.41        0.38    s\n",
      "49     0.2749       83.90        0.7914       82.41        0.41    s\n",
      "49     0.2749       83.90        0.7914       82.41        0.41    s\n",
      "50     0.2685       86.88        0.8624       82.41        0.39    s\n",
      "\n",
      "✓ Compact model training complete!\n",
      "  Best validation loss: 0.6099\n",
      "  Final train accuracy: 86.88%\n",
      "  Final val accuracy: 82.41%\n",
      "\n",
      "Compact Model Test Results:\n",
      "  Test Accuracy: 82.41%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Noise      0.741     0.956     0.835        45\n",
      "     Traffic      0.000     0.000     0.000         3\n",
      "  Earthquake      0.939     0.767     0.844        60\n",
      "\n",
      "    accuracy                          0.824       108\n",
      "   macro avg      0.560     0.574     0.560       108\n",
      "weighted avg      0.830     0.824     0.817       108\n",
      "\n",
      "\n",
      "✓ Model saved to: ../../models/seismic_cnn_compact_20251210_195829.pth\n",
      "50     0.2685       86.88        0.8624       82.41        0.39    s\n",
      "\n",
      "✓ Compact model training complete!\n",
      "  Best validation loss: 0.6099\n",
      "  Final train accuracy: 86.88%\n",
      "  Final val accuracy: 82.41%\n",
      "\n",
      "Compact Model Test Results:\n",
      "  Test Accuracy: 82.41%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Noise      0.741     0.956     0.835        45\n",
      "     Traffic      0.000     0.000     0.000         3\n",
      "  Earthquake      0.939     0.767     0.844        60\n",
      "\n",
      "    accuracy                          0.824       108\n",
      "   macro avg      0.560     0.574     0.560       108\n",
      "weighted avg      0.830     0.824     0.817       108\n",
      "\n",
      "\n",
      "✓ Model saved to: ../../models/seismic_cnn_compact_20251210_195829.pth\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 215\u001b[0m\n\u001b[1;32m    203\u001b[0m     all_results[model_type] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: model,\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m: history,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_path\u001b[39m\u001b[38;5;124m'\u001b[39m: model_path\n\u001b[1;32m    212\u001b[0m     }\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# Small delay between models\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALL MODELS TRAINED SUCCESSFULLY!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Loss function (with class weights for imbalanced data)\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)  # Normalize\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "print(f\"Class weights for loss function:\")\n",
    "for i, (name, weight) in enumerate(zip(class_names, class_weights)):\n",
    "    print(f\"  {name}: {weight:.3f}\")\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100 * correct / total\n",
    "\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100 * correct / total\n",
    "\n",
    "\n",
    "def train_model(model, model_type, train_loader, val_loader, criterion, num_epochs, learning_rate, weight_decay, device):\n",
    "    \"\"\"Train a model and return history and best state.\"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training {model_type.upper()} Model ({n_params:,} parameters)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"{'Epoch':<6} {'Train Loss':<12} {'Train Acc':<12} {'Val Loss':<12} {'Val Acc':<12} {'Time':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"{epoch+1:<6} {train_loss:<12.4f} {train_acc:<12.2f} {val_loss:<12.4f} {val_acc:<12.2f} {epoch_time:<8.2f}s\")\n",
    "    \n",
    "    print(f\"\\n✓ {model_type.capitalize()} model training complete!\")\n",
    "    print(f\"  Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"  Final train accuracy: {history['train_acc'][-1]:.2f}%\")\n",
    "    print(f\"  Final val accuracy: {history['val_acc'][-1]:.2f}%\")\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return history, best_val_loss, n_params\n",
    "\n",
    "\n",
    "# Store results for all models\n",
    "all_results = {}\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path(\"../../models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Train each model\n",
    "for model_type in models_to_train:\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"# TRAINING {model_type.upper()} MODEL\")\n",
    "    print(f\"{'#'*70}\\n\")\n",
    "    \n",
    "    # Initialize model\n",
    "    if model_type == 'standard':\n",
    "        model = SeismicCNN(\n",
    "            num_classes=num_classes,\n",
    "            input_channels=input_channels,\n",
    "            input_length=input_length,\n",
    "            dropout_rate=0.3\n",
    "        )\n",
    "    else:\n",
    "        model = CompactSeismicCNN(\n",
    "            num_classes=num_classes,\n",
    "            input_channels=input_channels,\n",
    "            input_length=input_length\n",
    "        )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create loss function for this model\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    \n",
    "    # Train the model\n",
    "    history, best_val_loss, n_params = train_model(\n",
    "        model, model_type, train_loader, val_loader, criterion,\n",
    "        num_epochs, learning_rate, weight_decay, device\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_proba = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_proba.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_proba = np.array(y_proba)\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_type.capitalize()} Model Test Results:\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=3))\n",
    "    \n",
    "    # Save model\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_filename = f\"seismic_cnn_{model_type}_{timestamp}.pth\"\n",
    "    model_path = models_dir / model_filename\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_type': model_type,\n",
    "        'num_classes': num_classes,\n",
    "        'input_channels': input_channels,\n",
    "        'input_length': input_length,\n",
    "        'class_names': class_names,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'history': history,\n",
    "        'training_config': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'weight_decay': weight_decay\n",
    "        }\n",
    "    }, model_path)\n",
    "    \n",
    "    print(f\"\\n✓ Model saved to: {model_path}\")\n",
    "    \n",
    "    # Store results\n",
    "    all_results[model_type] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'n_params': n_params,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'y_proba': y_proba,\n",
    "        'model_path': model_path\n",
    "    }\n",
    "    \n",
    "    # Small delay between models\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ALL MODELS TRAINED SUCCESSFULLY!\")\n",
    "print(f\"{'='*70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6123d",
   "metadata": {},
   "source": [
    "## Compare Model Performance\n",
    "\n",
    "Visualize training history and compare both models side-by-side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves for both models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "colors = {'compact': 'blue', 'standard': 'orange'}\n",
    "line_styles = {'train': '-', 'val': '--'}\n",
    "\n",
    "# Loss comparison\n",
    "ax = axes[0, 0]\n",
    "for model_type in models_to_train:\n",
    "    history = all_results[model_type]['history']\n",
    "    ax.plot(history['train_loss'], label=f'{model_type.capitalize()} Train', \n",
    "            color=colors[model_type], linestyle=line_styles['train'], linewidth=2)\n",
    "    ax.plot(history['val_loss'], label=f'{model_type.capitalize()} Val', \n",
    "            color=colors[model_type], linestyle=line_styles['val'], linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training and Validation Loss Comparison', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy comparison\n",
    "ax = axes[0, 1]\n",
    "for model_type in models_to_train:\n",
    "    history = all_results[model_type]['history']\n",
    "    ax.plot(history['train_acc'], label=f'{model_type.capitalize()} Train', \n",
    "            color=colors[model_type], linestyle=line_styles['train'], linewidth=2)\n",
    "    ax.plot(history['val_acc'], label=f'{model_type.capitalize()} Val', \n",
    "            color=colors[model_type], linestyle=line_styles['val'], linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Training and Validation Accuracy Comparison', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Model comparison bar chart - Test Accuracy\n",
    "ax = axes[1, 0]\n",
    "model_names = [m.capitalize() for m in models_to_train]\n",
    "test_accs = [all_results[m]['test_accuracy'] * 100 for m in models_to_train]\n",
    "params = [all_results[m]['n_params'] for m in models_to_train]\n",
    "\n",
    "bars = ax.bar(model_names, test_accs, color=[colors[m] for m in models_to_train], alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Test Accuracy Comparison', fontsize=14)\n",
    "ax.set_ylim([0, 100])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, test_accs):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.2f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Model comparison - Parameters\n",
    "ax = axes[1, 1]\n",
    "bars = ax.bar(model_names, params, color=[colors[m] for m in models_to_train], alpha=0.7, edgecolor='black')\n",
    "ax.set_ylabel('Number of Parameters', fontsize=12)\n",
    "ax.set_title('Model Size Comparison', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, param in zip(bars, params):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{param:,}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<15} {'Parameters':<15} {'Test Accuracy':<15} {'Saved To':<30}\")\n",
    "print(\"-\"*70)\n",
    "for model_type in models_to_train:\n",
    "    result = all_results[model_type]\n",
    "    print(f\"{model_type.capitalize():<15} {result['n_params']:<15,} {result['test_accuracy']*100:<15.2f} {result['model_path'].name:<30}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c6e3c",
   "metadata": {},
   "source": [
    "## Confusion Matrices for Both Models\n",
    "\n",
    "Compare confusion matrices to see how each model performs on different classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for both models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "for idx, model_type in enumerate(models_to_train):\n",
    "    y_true = all_results[model_type]['y_true']\n",
    "    y_pred = all_results[model_type]['y_pred']\n",
    "    \n",
    "    # Compute confusion matrices\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Raw counts\n",
    "    ax = axes[idx, 0]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, \n",
    "                yticklabels=class_names, ax=ax, cbar_kws={'label': 'Count'})\n",
    "    ax.set_xlabel('Predicted', fontsize=11)\n",
    "    ax.set_ylabel('True', fontsize=11)\n",
    "    ax.set_title(f'{model_type.capitalize()} - Confusion Matrix (Counts)', fontsize=13)\n",
    "    \n",
    "    # Normalized\n",
    "    ax = axes[idx, 1]\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names,\n",
    "                yticklabels=class_names, ax=ax, cbar_kws={'label': 'Proportion'})\n",
    "    ax.set_xlabel('Predicted', fontsize=11)\n",
    "    ax.set_ylabel('True', fontsize=11)\n",
    "    ax.set_title(f'{model_type.capitalize()} - Confusion Matrix (Normalized)', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrices plotted for both models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdc9d4",
   "metadata": {},
   "source": [
    "## Example Predictions\n",
    "\n",
    "Visualize predictions from the compact model on test examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use compact model for visualization\n",
    "model_type = 'compact'\n",
    "y_pred = all_results[model_type]['y_pred']\n",
    "y_proba = all_results[model_type]['y_proba']\n",
    "\n",
    "# Select random examples from test set\n",
    "n_examples = 9\n",
    "random_indices = np.random.choice(len(X_test), n_examples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get waveform\n",
    "    waveform = X_test[idx, 0, :]  # Remove channel dimension\n",
    "    true_label = y_test[idx]\n",
    "    pred_label = y_pred[idx]\n",
    "    proba = y_proba[idx]\n",
    "    \n",
    "    # Plot waveform\n",
    "    time_axis = np.arange(len(waveform)) / 100.0  # Assuming 100 Hz\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    ax.plot(time_axis, waveform, color=color, linewidth=1)\n",
    "    \n",
    "    # Title with prediction info\n",
    "    title = f\"True: {class_names[true_label]}, Pred: {class_names[pred_label]}\\n\"\n",
    "    title += f\"Conf: {proba[pred_label]*100:.1f}%\"\n",
    "    ax.set_title(title, fontsize=10, color=color)\n",
    "    ax.set_xlabel('Time (s)', fontsize=9)\n",
    "    ax.set_ylabel('Amplitude', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Test Predictions - {model_type.capitalize()} Model (Green=Correct, Red=Incorrect)', \n",
    "             fontsize=14, y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Example predictions visualized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e467e",
   "metadata": {},
   "source": [
    "## Training Summary\n",
    "\n",
    "Both models have been saved. Review the final summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65513d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_type in models_to_train:\n",
    "    result = all_results[model_type]\n",
    "    print(f\"\\n{model_type.upper()} MODEL:\")\n",
    "    print(f\"  Parameters: {result['n_params']:,}\")\n",
    "    print(f\"  Test Accuracy: {result['test_accuracy']*100:.2f}%\")\n",
    "    print(f\"  Saved to: {result['model_path']}\")\n",
    "    \n",
    "    # Save training summary\n",
    "    timestamp = result['model_path'].stem.split('_')[-1]\n",
    "    summary_file = models_dir / f\"training_summary_{model_type}_{timestamp}.txt\"\n",
    "    \n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(f\"Seismic CNN Training Summary - {model_type.upper()} Model\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Model Configuration:\\n\")\n",
    "        f.write(f\"  Type: {model_type}\\n\")\n",
    "        f.write(f\"  Parameters: {result['n_params']:,}\\n\")\n",
    "        f.write(f\"  Input shape: (batch, {input_channels}, {input_length})\\n\")\n",
    "        f.write(f\"  Number of classes: {num_classes}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Training Configuration:\\n\")\n",
    "        f.write(f\"  Epochs: {num_epochs}\\n\")\n",
    "        f.write(f\"  Batch size: {batch_size}\\n\")\n",
    "        f.write(f\"  Learning rate: {learning_rate}\\n\")\n",
    "        f.write(f\"  Weight decay: {weight_decay}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Dataset Split:\\n\")\n",
    "        f.write(f\"  Train: {len(X_train)} samples\\n\")\n",
    "        f.write(f\"  Validation: {len(X_val)} samples\\n\")\n",
    "        f.write(f\"  Test: {len(X_test)} samples\\n\\n\")\n",
    "        \n",
    "        history = result['history']\n",
    "        f.write(\"Results:\\n\")\n",
    "        f.write(f\"  Best validation loss: {min(history['val_loss']):.4f}\\n\")\n",
    "        f.write(f\"  Final train accuracy: {history['train_acc'][-1]:.2f}%\\n\")\n",
    "        f.write(f\"  Final val accuracy: {history['val_acc'][-1]:.2f}%\\n\")\n",
    "        f.write(f\"  Test accuracy: {result['test_accuracy']*100:.2f}%\\n\\n\")\n",
    "        \n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(classification_report(result['y_true'], result['y_pred'], \n",
    "                                     target_names=class_names, digits=3))\n",
    "    \n",
    "    print(f\"  Summary saved to: {summary_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Both models trained and saved successfully!\")\n",
    "print(f\"Models directory: {models_dir}\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisepy-deploy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
